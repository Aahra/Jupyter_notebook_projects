{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Improving a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First predictions  = baseline predictions\n",
    "First model = baseline models \n",
    "\n",
    "From a data perspective \n",
    "* Could you collect more data?(more data,more better)\n",
    "* Could you improve the data ?\n",
    "\n",
    "From a model perspective \n",
    "* Could there be a better model to use?\n",
    "* Could we improve the current model ?\n",
    "\n",
    "Parameters vs Hyperparameters\n",
    "\n",
    "* Parameters :- models find these patterns in data\n",
    "* Hyperparameters :-settings on a model you can adjust to improve its ability to find patterns \n",
    "\n",
    "Ways to adjust hyperparameters\n",
    "\n",
    "1. by hand\n",
    "2. Randomnly by RandomSearchCV\n",
    "3. Exhaustively by GndSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston;\n",
    "\n",
    "boston_df = pd.DataFrame(boston[\"data\"],columns = boston [\"feature_names\"])\n",
    "boston_df[\"target\"]=pd.Series(boston[\"target\"])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning Hyperparameters by hand\n",
    "\n",
    "Lets make 3 sets :- training,validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
    "def evaluate_preds(Y_true,Y_preds):\n",
    "    accuracy=accuracy_score(Y_true,Y_preds)\n",
    "    precision=precision_score(Y_true,Y_preds)\n",
    "    recall=recall_score(Y_true,Y_preds)\n",
    "    f1=f1_score(Y_true,Y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy,2),\n",
    "                  \"precision\": round(precision,2),\n",
    "                  \"recall\": round(recall,2),\n",
    "                  \"f1\": round(f1,2)}\n",
    "    print(f\"Accuracy {accuracy*100:.2f}%\")\n",
    "    print(f\"precision {precision:.2f}\")\n",
    "    print(f\"recall {recall:.2f}\")\n",
    "    print(f\"f1 {f1:.2f}\")\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease= pd.read_csv(\"data/original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 82.22%\n",
      "precision 0.81\n",
      "recall 0.88\n",
      "f1 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82, 'precision': 0.81, 'recall': 0.88, 'f1': 0.85}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(42)\n",
    "\n",
    "#shuffle data\n",
    "heart_disease_shuffle = heart_disease.sample(frac=1)\n",
    "\n",
    "X=heart_disease_shuffle.drop(\"target\",axis=1)\n",
    "Y=heart_disease_shuffle[\"target\"]\n",
    "\n",
    "train_split = round(0.7* len(heart_disease_shuffle)) # 70% of data\n",
    "valid_split = round(train_split+0.15 * len(heart_disease_shuffle)) # 15% of data\n",
    "\n",
    "X_train,Y_train= X[:train_split],Y[:train_split]\n",
    "\n",
    "X_valid,Y_valid = X[train_split:valid_split],Y[train_split:valid_split]\n",
    "\n",
    "X_test,Y_test = X[valid_split:],Y[valid_split:]\n",
    "\n",
    "len(X_test)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "# make baseline predictions \n",
    "Y_preds = clf.predict(X_valid)\n",
    "\n",
    "# evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(Y_valid,Y_preds)\n",
    "baseline_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 82.22%\n",
      "precision 0.81\n",
      "recall 0.88\n",
      "f1 0.85\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# create a second a classfier with different hyperparameters\n",
    "\n",
    "clf_2= RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "clf_2.fit(X_train,Y_train)\n",
    "Y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "baseline_metrics_2 = evaluate_preds(Y_valid,Y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning with randomizedsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.0s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   2.6s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   2.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, total=   2.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   2.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   2.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   2.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, total=   2.4s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   2.7s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   2.9s\n",
      "[CV] n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=5, total=   2.7s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=100, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=6, min_samples_leaf=1, max_features=sqrt, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=30, total=   0.0s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=4, max_features=auto, max_depth=20, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   41.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100, n_jobs...\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [10, 100, 200, 1000,\n",
       "                                                         1200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "grid ={\"n_estimators\" : [10,100,200,1000,1200],\n",
    "      \"max_depth\" : [None,5,10,20,30],\n",
    "        \"max_features\" : [\"auto\",\"sqrt\"],\n",
    "        \"min_samples_split\" : [2,4,6],\n",
    "       \"min_samples_leaf\" :[1,2,4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# split into X and Y\n",
    "\n",
    "X =heart_disease_shuffle.drop(\"target\",axis = 1)\n",
    "Y = heart_disease_shuffle[\"target\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size= 0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "rs_clf =RandomizedSearchCV(estimator= clf,\n",
    "                           param_distributions = grid,\n",
    "                          n_iter=10,\n",
    "                          cv=5,\n",
    "                           verbose=2)\n",
    "\n",
    "rs_clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 83.61%\n",
      "precision 0.78\n",
      "recall 0.89\n",
      "f1 0.83\n"
     ]
    }
   ],
   "source": [
    "rs_Y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "rs_metrics = evaluate_preds(Y_test,rs_Y_preds\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
